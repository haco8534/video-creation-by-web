// Auto-generated by generate-subtitle-data.js
// Source: diffusion_model
// Generated at: 2026-02-25T05:44:16.389Z

export interface SubtitleEntry {
    startTimeSec: number;
    startFrame: number;
    durationSec: number;
    durationFrames: number;
    speaker: string;
    text: string;
    speakerColor: string;
    sceneId: number;
    sceneTitle: string;
}

export const FPS = 30;
export const TOTAL_DURATION_SEC = 933.5;
export const TOTAL_FRAMES = 28005;

export const SUBTITLE_DATA: SubtitleEntry[] = [
  {
    "startTimeSec": 4,
    "startFrame": 120,
    "durationSec": 1.7066666666666668,
    "durationFrames": 51,
    "speaker": "めたん",
    "text": "今日はどんなお話ですの?",
    "speakerColor": "#d6336c",
    "sceneId": 1,
    "sceneTitle": "AIは描くのではなく見つけ出す"
  },
  {
    "startTimeSec": 6.006666666666667,
    "startFrame": 180,
    "durationSec": 6.464,
    "durationFrames": 194,
    "speaker": "ずんだもん",
    "text": "今日は、画像生成AIがどうやって絵を作っているのか、その仕組みを全部解説するのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 1,
    "sceneTitle": "AIは描くのではなく見つけ出す"
  },
  {
    "startTimeSec": 12.770666666666667,
    "startFrame": 383,
    "durationSec": 10.357333333333333,
    "durationFrames": 311,
    "speaker": "めたん",
    "text": "Stable DiffusionとかMidjourneyとか、最近すごいですわよね。テキストを入れるだけで絵が出てくるんですもの。",
    "speakerColor": "#d6336c",
    "sceneId": 1,
    "sceneTitle": "AIは描くのではなく見つけ出す"
  },
  {
    "startTimeSec": 23.428,
    "startFrame": 703,
    "durationSec": 8.458666666666666,
    "durationFrames": 254,
    "speaker": "ずんだもん",
    "text": "そうなのだ。でもここで一つ質問なのだ。AIが描いた絵って、実は砂嵐のテレビから始まってるって知ってたのだ?",
    "speakerColor": "#22c55e",
    "sceneId": 1,
    "sceneTitle": "AIは描くのではなく見つけ出す"
  },
  {
    "startTimeSec": 32.18666666666667,
    "startFrame": 966,
    "durationSec": 5.354666666666667,
    "durationFrames": 161,
    "speaker": "めたん",
    "text": "え?砂嵐?あの地上波が終わった後に出てくるザーッていうやつですの?",
    "speakerColor": "#d6336c",
    "sceneId": 1,
    "sceneTitle": "AIは描くのではなく見つけ出す"
  },
  {
    "startTimeSec": 37.84133333333333,
    "startFrame": 1135,
    "durationSec": 11.2,
    "durationFrames": 336,
    "speaker": "ずんだもん",
    "text": "そうなのだ。多くの人はAIが人間みたいに筆を動かして絵を描いているとか、ネット上の画像を切り貼りしていると思っているのだ。でも実際は全然違うのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 1,
    "sceneTitle": "AIは描くのではなく見つけ出す"
  },
  {
    "startTimeSec": 49.34133333333333,
    "startFrame": 1480,
    "durationSec": 1.536,
    "durationFrames": 46,
    "speaker": "めたん",
    "text": "じゃあ何をしてるんですの?",
    "speakerColor": "#d6336c",
    "sceneId": 1,
    "sceneTitle": "AIは描くのではなく見つけ出す"
  },
  {
    "startTimeSec": 51.17733333333333,
    "startFrame": 1535,
    "durationSec": 12.885333333333334,
    "durationFrames": 387,
    "speaker": "ずんだもん",
    "text": "AIは、完全にランダムなノイズ、つまり砂嵐みたいな画像の中から、少しずつパターンを見つけ出して、画像を浮かび上がらせているのだ。描いているんじゃなくて、見つけ出しているのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 1,
    "sceneTitle": "AIは描くのではなく見つけ出す"
  },
  {
    "startTimeSec": 64.36266666666667,
    "startFrame": 1931,
    "durationSec": 3.872,
    "durationFrames": 116,
    "speaker": "めたん",
    "text": "砂嵐から画像を見つけ出す、にわかには信じがたいですわね。",
    "speakerColor": "#d6336c",
    "sceneId": 1,
    "sceneTitle": "AIは描くのではなく見つけ出す"
  },
  {
    "startTimeSec": 68.53466666666667,
    "startFrame": 2056,
    "durationSec": 16.010666666666665,
    "durationFrames": 480,
    "speaker": "ずんだもん",
    "text": "不思議に聞こえるだろう?でもこれは比喩じゃなくて本当にそうなのだ。今日はその仕組みを拡散モデルの原理から全部説明するのだ。この動画を見終わる頃には、画像生成AIの中で何が起きているのか、全部わかるようになるのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 1,
    "sceneTitle": "AIは描くのではなく見つけ出す"
  },
  {
    "startTimeSec": 84.84533333333333,
    "startFrame": 2545,
    "durationSec": 2.538666666666667,
    "durationFrames": 76,
    "speaker": "めたん",
    "text": "楽しみですわ!早く教えてくださいな。",
    "speakerColor": "#d6336c",
    "sceneId": 1,
    "sceneTitle": "AIは描くのではなく見つけ出す"
  },
  {
    "startTimeSec": 87.684,
    "startFrame": 2631,
    "durationSec": 10.101333333333333,
    "durationFrames": 303,
    "speaker": "ずんだもん",
    "text": "もちろんなのだ。でもその前に、ちょっとだけ歴史の話をさせてほしいのだ。そもそも画像を自動で作るAIってのは拡散モデルが最初じゃないのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 1,
    "sceneTitle": "AIは描くのではなく見つけ出す"
  },
  {
    "startTimeSec": 98.3,
    "startFrame": 2949,
    "durationSec": 15.189333333333334,
    "durationFrames": 456,
    "speaker": "ずんだもん",
    "text": "画像を自動で作り出すAIの研究は、ざっくり3つの世代に分けられるのだ。最初は2013年のブイエーイー、次が2014年のガン、そして今の主流が2020年に実用化された拡散モデルなのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 2,
    "sceneTitle": "画像生成AIの歴史"
  },
  {
    "startTimeSec": 113.78933333333333,
    "startFrame": 3414,
    "durationSec": 3.7013333333333334,
    "durationFrames": 111,
    "speaker": "めたん",
    "text": "ガンって聞いたことありますわ。一時期話題になってましたわよね。",
    "speakerColor": "#d6336c",
    "sceneId": 2,
    "sceneTitle": "画像生成AIの歴史"
  },
  {
    "startTimeSec": 117.79066666666667,
    "startFrame": 3534,
    "durationSec": 5.365333333333333,
    "durationFrames": 161,
    "speaker": "ずんだもん",
    "text": "そうなのだ。ガンは約6年間、画像生成AIの王様だったのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 2,
    "sceneTitle": "画像生成AIの歴史"
  },
  {
    "startTimeSec": 123.69999999999999,
    "startFrame": 3711,
    "durationSec": 20.064,
    "durationFrames": 602,
    "speaker": "ずんだもん",
    "text": "ガンの仕組みを簡単にたとえると、偽造者と鑑定士の対決なのだ。偽造者が偽物の画像を作って、鑑定士がこれは偽物だぞと見破ろうとする。この対決を何十万回も繰り返すことで、偽造者の腕がどんどん上がって、最終的には本物そっくりの画像が作れるようになるのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 3,
    "sceneTitle": "GAN vs 拡散モデル"
  },
  {
    "startTimeSec": 144.064,
    "startFrame": 4322,
    "durationSec": 4.128,
    "durationFrames": 124,
    "speaker": "めたん",
    "text": "面白い仕組みですわね。でもそれが主流じゃなくなったのはなぜですの?",
    "speakerColor": "#d6336c",
    "sceneId": 3,
    "sceneTitle": "GAN vs 拡散モデル"
  },
  {
    "startTimeSec": 148.492,
    "startFrame": 4455,
    "durationSec": 10.901333333333334,
    "durationFrames": 327,
    "speaker": "ずんだもん",
    "text": "対決形式には大きな弱点があったのだ。偽造者と鑑定士のバランスを取るのがものすごく難しくて、片方が強くなりすぎるとすぐに学習が破綻するのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 3,
    "sceneTitle": "GAN vs 拡散モデル"
  },
  {
    "startTimeSec": 159.69333333333333,
    "startFrame": 4791,
    "durationSec": 2.816,
    "durationFrames": 84,
    "speaker": "めたん",
    "text": "どちらかが圧勝してしまうと成り立たないんですのね。",
    "speakerColor": "#d6336c",
    "sceneId": 3,
    "sceneTitle": "GAN vs 拡散モデル"
  },
  {
    "startTimeSec": 162.8093333333333,
    "startFrame": 4884,
    "durationSec": 11.402666666666667,
    "durationFrames": 342,
    "speaker": "ずんだもん",
    "text": "そうなのだ。さらにモード崩壊って言って、偽造者がこの手の画像なら鑑定士を騙せるって学習してしまうと、同じような画像ばかり生成してしまう問題もあったのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 3,
    "sceneTitle": "GAN vs 拡散モデル"
  },
  {
    "startTimeSec": 174.7,
    "startFrame": 5241,
    "durationSec": 5.034666666666666,
    "durationFrames": 151,
    "speaker": "めたん",
    "text": "なるほど、それは困りますわね。で、拡散モデルはどう違うんですの?",
    "speakerColor": "#d6336c",
    "sceneId": 4,
    "sceneTitle": "拡散モデルが主流になった理由"
  },
  {
    "startTimeSec": 180.03466666666665,
    "startFrame": 5401,
    "durationSec": 19.552,
    "durationFrames": 587,
    "speaker": "ずんだもん",
    "text": "拡散モデルは対決なんか一切しないのだ。やっていることはもっとシンプルで、画像に加えられたノイズを予測するという1つのタスクだけを学習するのだ。対戦相手がいないから、バランス調整の問題が起きない。だから学習が非常に安定していて、多様な画像を生成できるのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 4,
    "sceneTitle": "拡散モデルが主流になった理由"
  },
  {
    "startTimeSec": 199.88666666666666,
    "startFrame": 5997,
    "durationSec": 4.778666666666667,
    "durationFrames": 143,
    "speaker": "めたん",
    "text": "対決じゃなくて、お掃除みたいな感じですのね。汚れを見つけて取り除くだけ。",
    "speakerColor": "#d6336c",
    "sceneId": 4,
    "sceneTitle": "拡散モデルが主流になった理由"
  },
  {
    "startTimeSec": 204.96533333333332,
    "startFrame": 6149,
    "durationSec": 10.549333333333333,
    "durationFrames": 316,
    "speaker": "ずんだもん",
    "text": "まさにそうなのだ。イメージとしてはお掃除ロボットに近いのだ。で、この拡散モデルが具体的にどんな仕組みで動いているのか、ここからが本題なのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 4,
    "sceneTitle": "拡散モデルが主流になった理由"
  },
  {
    "startTimeSec": 219,
    "startFrame": 6570,
    "durationSec": 4.757333333333333,
    "durationFrames": 143,
    "speaker": "めたん",
    "text": "いよいよ本題ですわね。拡散モデルって、そもそもどういう仕組みなんですの?",
    "speakerColor": "#d6336c",
    "sceneId": 6,
    "sceneTitle": "Forward Process"
  },
  {
    "startTimeSec": 224.05733333333333,
    "startFrame": 6722,
    "durationSec": 13.386666666666667,
    "durationFrames": 402,
    "speaker": "ずんだもん",
    "text": "拡散モデルの原理は、実は物理学から来ているのだ。2015年にスタンフォード大学のソールディクスタインっていう研究者が、非平衡熱力学っていう物理の分野からヒントを得て考案したのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 6,
    "sceneTitle": "Forward Process"
  },
  {
    "startTimeSec": 237.744,
    "startFrame": 7132,
    "durationSec": 2.848,
    "durationFrames": 85,
    "speaker": "めたん",
    "text": "非平衡熱力学、難しそうですわね。",
    "speakerColor": "#d6336c",
    "sceneId": 6,
    "sceneTitle": "Forward Process"
  },
  {
    "startTimeSec": 240.892,
    "startFrame": 7227,
    "durationSec": 18.656,
    "durationFrames": 560,
    "speaker": "ずんだもん",
    "text": "言葉は難しいけど、原理はシンプルなのだ。水にインクを一滴垂らすと、最初はくっきりした色の塊なのに、時間が経つとだんだん広がって、最終的には全体が均一にぼんやりしてしまうのだ。これが物理学でいう拡散で、拡散モデルの名前の由来なのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 6,
    "sceneTitle": "Forward Process"
  },
  {
    "startTimeSec": 259.848,
    "startFrame": 7795,
    "durationSec": 5.578666666666667,
    "durationFrames": 167,
    "speaker": "めたん",
    "text": "なるほど。インクが広がるイメージですのね。それが画像生成と何の関係がありますの?",
    "speakerColor": "#d6336c",
    "sceneId": 6,
    "sceneTitle": "Forward Process"
  },
  {
    "startTimeSec": 265.7266666666667,
    "startFrame": 7972,
    "durationSec": 20.096,
    "durationFrames": 603,
    "speaker": "ずんだもん",
    "text": "拡散モデルでは、きれいな画像にちょっとずつノイズを加えていくのだ。ステップ1では画像がほんの少しだけザラザラする。ステップ2ではもう少しザラザラになる。これを何百回も繰り返すと、最終的には元の画像が何だったか全くわからない、完全なノイズ、つまり砂嵐になるのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 6,
    "sceneTitle": "Forward Process"
  },
  {
    "startTimeSec": 286.1226666666667,
    "startFrame": 8584,
    "durationSec": 3.7866666666666666,
    "durationFrames": 114,
    "speaker": "めたん",
    "text": "わざと画像を壊していくんですの?何のためにそんなことを?",
    "speakerColor": "#d6336c",
    "sceneId": 6,
    "sceneTitle": "Forward Process"
  },
  {
    "startTimeSec": 290.20933333333335,
    "startFrame": 8706,
    "durationSec": 12.746666666666666,
    "durationFrames": 382,
    "speaker": "ずんだもん",
    "text": "いい質問なのだ。この壊す過程はフォワードプロセスって呼ばれていて、ここではAIの学習は何も行われないのだ。ただ機械的にノイズを乗せていくだけなのだ。大事なのはこの次なのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 6,
    "sceneTitle": "Forward Process"
  },
  {
    "startTimeSec": 303.5,
    "startFrame": 9105,
    "durationSec": 18.165333333333333,
    "durationFrames": 545,
    "speaker": "ずんだもん",
    "text": "今度は逆に、完全なノイズの状態からスタートして、少しずつノイズを取り除いていくのだ。ステップ1ではうっすらと輪郭が見え始める。ステップ2ではもう少し形がはっきりしてくる。これを繰り返していくと、最終的にはきれいな画像が浮かび上がってくるのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 7,
    "sceneTitle": "Reverse Process"
  },
  {
    "startTimeSec": 321.9653333333333,
    "startFrame": 9659,
    "durationSec": 6.112,
    "durationFrames": 183,
    "speaker": "めたん",
    "text": "壊す、戻すってことですのね。まるで彫刻みたいですわ。大理石の塊から像を掘り出すような。",
    "speakerColor": "#d6336c",
    "sceneId": 7,
    "sceneTitle": "Reverse Process"
  },
  {
    "startTimeSec": 328.3773333333333,
    "startFrame": 9851,
    "durationSec": 9.141333333333334,
    "durationFrames": 274,
    "speaker": "ずんだもん",
    "text": "おっ、いいたとえなのだ。実際そのイメージに近いのだ。で、ここで重要なのはAIはどうやって戻し方を知るのかなのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 7,
    "sceneTitle": "Reverse Process"
  },
  {
    "startTimeSec": 337.8186666666666,
    "startFrame": 10135,
    "durationSec": 4.16,
    "durationFrames": 125,
    "speaker": "めたん",
    "text": "そうですわね。壊すのは簡単でも、戻すのは難しそうですわ。",
    "speakerColor": "#d6336c",
    "sceneId": 7,
    "sceneTitle": "Reverse Process"
  },
  {
    "startTimeSec": 342.2786666666666,
    "startFrame": 10268,
    "durationSec": 18.645333333333333,
    "durationFrames": 559,
    "speaker": "ずんだもん",
    "text": "ここがポイントなのだ。AIに大量の画像で壊す、戻すの練習をさせるのだ。何百万枚もの画像に対して、いろんな段階でノイズを加えて、そのノイズを取り除く練習を繰り返すのだ。猫の画像でも風景の画像でも、ありとあらゆる画像で練習するのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 7,
    "sceneTitle": "Reverse Process"
  },
  {
    "startTimeSec": 361.4,
    "startFrame": 10842,
    "durationSec": 2.570666666666667,
    "durationFrames": 77,
    "speaker": "めたん",
    "text": "でもそれって膨大な計算になりませんの?",
    "speakerColor": "#d6336c",
    "sceneId": 8,
    "sceneTitle": "ノイズε予測"
  },
  {
    "startTimeSec": 364.27066666666667,
    "startFrame": 10928,
    "durationSec": 18.453333333333333,
    "durationFrames": 554,
    "speaker": "ずんだもん",
    "text": "実はここに美しい発見があるのだ。2020年にジョナサンホーらの研究チームが発表したDDPMっていう論文で、学習の目標をものすごくシンプルにできることが示されたのだ。やるべきことはたった1つ、この画像にどんなノイズが加えられたかを予測するだけなのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 8,
    "sceneTitle": "ノイズε予測"
  },
  {
    "startTimeSec": 383.024,
    "startFrame": 11491,
    "durationSec": 4.245333333333333,
    "durationFrames": 127,
    "speaker": "めたん",
    "text": "ノイズを予測するだけ!?それだけであんなすごい画像が作れるんですの?",
    "speakerColor": "#d6336c",
    "sceneId": 8,
    "sceneTitle": "ノイズε予測"
  },
  {
    "startTimeSec": 387.56933333333336,
    "startFrame": 11627,
    "durationSec": 15.488,
    "durationFrames": 465,
    "speaker": "ずんだもん",
    "text": "そうなのだ。数学的にはイプシロンって呼ばれるノイズ成分を予測するだけで、結果的に画像全体を復元できることが証明されたのだ。画像を丸ごと予測するんじゃなくて、このステップでどれだけ汚れが乗ったかだけ当てればいいのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 8,
    "sceneTitle": "ノイズε予測"
  },
  {
    "startTimeSec": 403.3573333333334,
    "startFrame": 12101,
    "durationSec": 2.016,
    "durationFrames": 60,
    "speaker": "めたん",
    "text": "シンプルだけど奥が深いですわね。",
    "speakerColor": "#d6336c",
    "sceneId": 8,
    "sceneTitle": "ノイズε予測"
  },
  {
    "startTimeSec": 405.67333333333335,
    "startFrame": 12170,
    "durationSec": 11.381333333333334,
    "durationFrames": 341,
    "speaker": "ずんだもん",
    "text": "このシンプルさこそが、拡散モデルの安定した学習を可能にしている鍵なのだ。ガンみたいに敵同士を戦わせる必要がないから、学習が途中で壊れにくいのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 8,
    "sceneTitle": "ノイズε予測"
  },
  {
    "startTimeSec": 417.3546666666667,
    "startFrame": 12521,
    "durationSec": 9.482666666666667,
    "durationFrames": 284,
    "speaker": "めたん",
    "text": "なるほど、原理はよくわかりましたわ。でも実際のStable Diffusionとかって、もうちょっと複雑なんじゃありませんの?",
    "speakerColor": "#d6336c",
    "sceneId": 8,
    "sceneTitle": "ノイズε予測"
  },
  {
    "startTimeSec": 427.13733333333334,
    "startFrame": 12814,
    "durationSec": 19.061333333333334,
    "durationFrames": 572,
    "speaker": "ずんだもん",
    "text": "いいところに気づいたのだ。実は、今の原理をそのまま使うと計算コストが大きすぎるのだ。512かける512の画像で直接ノイズ除去をすると、とてもじゃないけど一般のパソコンでは動かないのだ。だから実際の製品にはいくつもの天才的な工夫が加えられているのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 8,
    "sceneTitle": "ノイズε予測"
  },
  {
    "startTimeSec": 446.7,
    "startFrame": 13401,
    "durationSec": 15.722666666666667,
    "durationFrames": 472,
    "speaker": "ずんだもん",
    "text": "Stable Diffusionの中身には、大きく分けて3つの部品があるのだ。まずブイエーイーっていう圧縮装置、次にユーネットっていうノイズ除去エンジン、そしてまたブイエーイーの復元装置なのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 9,
    "sceneTitle": "Stable Diffusionの全体構造"
  },
  {
    "startTimeSec": 462.72266666666667,
    "startFrame": 13882,
    "durationSec": 4.981333333333334,
    "durationFrames": 149,
    "speaker": "めたん",
    "text": "3つの部品が連携してるんですのね。まず最初のブイエーイーって何をするんですの?",
    "speakerColor": "#d6336c",
    "sceneId": 9,
    "sceneTitle": "Stable Diffusionの全体構造"
  },
  {
    "startTimeSec": 468.2,
    "startFrame": 14046,
    "durationSec": 15.893333333333333,
    "durationFrames": 477,
    "speaker": "ずんだもん",
    "text": "ブイエーイーは画像を圧縮する役割なのだ。例えば512かける512ピクセルの画像があったとするだろう。これは約78万ピクセルもあるのだ。直接ノイズ除去しようとすると、とんでもない計算量が必要になるのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 10,
    "sceneTitle": "VAE圧縮 64分の1"
  },
  {
    "startTimeSec": 484.3933333333333,
    "startFrame": 14532,
    "durationSec": 3.018666666666667,
    "durationFrames": 91,
    "speaker": "めたん",
    "text": "78万ピクセル、確かに多いですわね。",
    "speakerColor": "#d6336c",
    "sceneId": 10,
    "sceneTitle": "VAE圧縮 64分の1"
  },
  {
    "startTimeSec": 487.712,
    "startFrame": 14631,
    "durationSec": 12.149333333333333,
    "durationFrames": 364,
    "speaker": "ずんだもん",
    "text": "だからブイエーイーが画像を潜在空間っていう小さな世界に圧縮するのだ。具体的には64かける64まで縮小するのだ。データ量にして約64分の1なのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 10,
    "sceneTitle": "VAE圧縮 64分の1"
  },
  {
    "startTimeSec": 500.16133333333335,
    "startFrame": 15005,
    "durationSec": 4.181333333333333,
    "durationFrames": 125,
    "speaker": "めたん",
    "text": "64分の1ですの!?そんなに小さくして大丈夫なんですの?",
    "speakerColor": "#d6336c",
    "sceneId": 10,
    "sceneTitle": "VAE圧縮 64分の1"
  },
  {
    "startTimeSec": 504.6426666666667,
    "startFrame": 15139,
    "durationSec": 19.029333333333334,
    "durationFrames": 571,
    "speaker": "ずんだもん",
    "text": "ブイエーイーは賢いのだ。ただ画像を縮小するんじゃなくて、画像の本質的な特徴、つまり形や色の傾向、テクスチャの情報だけを保存するのだ。いわば画像のエッセンスだけ取り出すイメージなのだ。細かいピクセル情報は捨てるけど、意味のある情報はちゃんと残すのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 10,
    "sceneTitle": "VAE圧縮 64分の1"
  },
  {
    "startTimeSec": 524.2,
    "startFrame": 15726,
    "durationSec": 15.669333333333332,
    "durationFrames": 470,
    "speaker": "ずんだもん",
    "text": "次がユーネットなのだ。これがノイズ除去の本体で、名前の通りU字の形をしたニューラルネットワークなのだ。圧縮された画像のノイズを予測して取り除くのだ。ここで面白いのは、ユーネットにはテキストの情報も入ってくるのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 11,
    "sceneTitle": "CLIP + Cross-Attention"
  },
  {
    "startTimeSec": 540.1693333333334,
    "startFrame": 16205,
    "durationSec": 6.485333333333333,
    "durationFrames": 195,
    "speaker": "めたん",
    "text": "テキストの情報?プロンプトのことですわね。どうやって文字の情報を画像生成に使っているんですの?",
    "speakerColor": "#d6336c",
    "sceneId": 11,
    "sceneTitle": "CLIP + Cross-Attention"
  },
  {
    "startTimeSec": 546.9546666666668,
    "startFrame": 16409,
    "durationSec": 9.653333333333334,
    "durationFrames": 290,
    "speaker": "ずんだもん",
    "text": "ユーザーが入力したプロンプト、例えば夕焼けの海辺を歩く猫は、まずクリップっていう別のAIがテキストを数値のベクトルに変換するのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 11,
    "sceneTitle": "CLIP + Cross-Attention"
  },
  {
    "startTimeSec": 556.9080000000001,
    "startFrame": 16707,
    "durationSec": 1.8986666666666667,
    "durationFrames": 57,
    "speaker": "めたん",
    "text": "言葉を数字に変えるんですのね。",
    "speakerColor": "#d6336c",
    "sceneId": 11,
    "sceneTitle": "CLIP + Cross-Attention"
  },
  {
    "startTimeSec": 559.1066666666668,
    "startFrame": 16773,
    "durationSec": 16.576,
    "durationFrames": 497,
    "speaker": "ずんだもん",
    "text": "そうなのだ。そしてそのベクトルが、ユーネットの中にあるクロスアテンションっていう仕組みを通じて、こういう雰囲気の画像にしてくれという指示を出すのだ。ノイズを除去するときに、テキストの意味を参考にしながら方向性を決める、いわばガイド役なのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 11,
    "sceneTitle": "CLIP + Cross-Attention"
  },
  {
    "startTimeSec": 575.9826666666668,
    "startFrame": 17279,
    "durationSec": 6.730666666666667,
    "durationFrames": 202,
    "speaker": "めたん",
    "text": "テキストがAIへのナビゲーターになるんですのね。砂嵐の中から猫っぽいものを探し出すためのヒントを与えてくれる。",
    "speakerColor": "#d6336c",
    "sceneId": 11,
    "sceneTitle": "CLIP + Cross-Attention"
  },
  {
    "startTimeSec": 583.0133333333334,
    "startFrame": 17490,
    "durationSec": 8.757333333333333,
    "durationFrames": 263,
    "speaker": "ずんだもん",
    "text": "まさにそうなのだ。さらにクラシファイアフリーガイダンスっていうテクニックで、プロンプトにどれくらい忠実に従うかも調整できるのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 11,
    "sceneTitle": "CLIP + Cross-Attention"
  },
  {
    "startTimeSec": 592.3000000000001,
    "startFrame": 17769,
    "durationSec": 11.648,
    "durationFrames": 349,
    "speaker": "ずんだもん",
    "text": "次に速度の工夫なのだ。元々の拡散モデルは、ノイズを除去するのに1000ステップも必要だったのだ。1枚の画像を作るのに1000回もAIを動かさないといけないのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 12,
    "sceneTitle": "DDIM高速化"
  },
  {
    "startTimeSec": 604.248,
    "startFrame": 18127,
    "durationSec": 1.888,
    "durationFrames": 57,
    "speaker": "めたん",
    "text": "それはさすがに遅すぎますわね。",
    "speakerColor": "#d6336c",
    "sceneId": 12,
    "sceneTitle": "DDIM高速化"
  },
  {
    "startTimeSec": 606.436,
    "startFrame": 18193,
    "durationSec": 19.050666666666668,
    "durationFrames": 572,
    "speaker": "ずんだもん",
    "text": "だからDDIMっていう高速化手法が開発されたのだ。これは1ステップずつ地道に進む代わりに、大きくジャンプしながらノイズを除去する方法なのだ。これを使うと、1000ステップを約50ステップまで減らせるのだ。約20倍の高速化で、しかも画質はほとんど落ちないのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 12,
    "sceneTitle": "DDIM高速化"
  },
  {
    "startTimeSec": 625.7866666666667,
    "startFrame": 18774,
    "durationSec": 2.7946666666666666,
    "durationFrames": 84,
    "speaker": "めたん",
    "text": "1000が50に!それはすごい進歩ですわね。",
    "speakerColor": "#d6336c",
    "sceneId": 12,
    "sceneTitle": "DDIM高速化"
  },
  {
    "startTimeSec": 628.8813333333334,
    "startFrame": 18866,
    "durationSec": 16.672,
    "durationFrames": 500,
    "speaker": "ずんだもん",
    "text": "こうした工夫、ブイエーイーによる圧縮、ユーネットとクロスアテンション、そしてDDIMによる高速化が全部組み合わさったおかげで、Stable Diffusionは一般の人のパソコンでも動くようになったのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 12,
    "sceneTitle": "DDIM高速化"
  },
  {
    "startTimeSec": 645.8533333333334,
    "startFrame": 19376,
    "durationSec": 1.984,
    "durationFrames": 60,
    "speaker": "めたん",
    "text": "すごい技術の積み重ねですわね。",
    "speakerColor": "#d6336c",
    "sceneId": 12,
    "sceneTitle": "DDIM高速化"
  },
  {
    "startTimeSec": 648.1373333333333,
    "startFrame": 19444,
    "durationSec": 4.586666666666667,
    "durationFrames": 138,
    "speaker": "ずんだもん",
    "text": "でもね、そんな拡散モデルにも、どうしても苦手なことがあるのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 12,
    "sceneTitle": "DDIM高速化"
  },
  {
    "startTimeSec": 656.2,
    "startFrame": 19686,
    "durationSec": 8.48,
    "durationFrames": 254,
    "speaker": "めたん",
    "text": "苦手なこと?そういえばAIが描いた絵って、手がおかしいことが多いですわよね。指が6本あったり、変な方向に曲がってたり。",
    "speakerColor": "#d6336c",
    "sceneId": 14,
    "sceneTitle": "手が描けない3つの理由"
  },
  {
    "startTimeSec": 664.98,
    "startFrame": 19949,
    "durationSec": 6.176,
    "durationFrames": 185,
    "speaker": "ずんだもん",
    "text": "まさにそれなのだ。実はAIが手を描くのが苦手なのには、ちゃんとした理由があるのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 14,
    "sceneTitle": "手が描けない3つの理由"
  },
  {
    "startTimeSec": 671.456,
    "startFrame": 20144,
    "durationSec": 13.482666666666667,
    "durationFrames": 404,
    "speaker": "ずんだもん",
    "text": "理由は大きく3つあるのだ。1つ目は、手の構造がめちゃくちゃ複雑だってこと。骨だけでも27本あって、関節は指だけで14個。指の曲がり方の組み合わせが膨大すぎるのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 14,
    "sceneTitle": "手が描けない3つの理由"
  },
  {
    "startTimeSec": 685.2386666666666,
    "startFrame": 20557,
    "durationSec": 3.712,
    "durationFrames": 111,
    "speaker": "めたん",
    "text": "確かに、手って体の中でも特に複雑な部位ですわよね。",
    "speakerColor": "#d6336c",
    "sceneId": 14,
    "sceneTitle": "手が描けない3つの理由"
  },
  {
    "startTimeSec": 689.2506666666666,
    "startFrame": 20678,
    "durationSec": 14.517333333333333,
    "durationFrames": 436,
    "speaker": "ずんだもん",
    "text": "2つ目は、学習データの問題なのだ。ネット上の画像って、手が小さく写っていたり、ぼやけていたり、物を持って隠れていたりすることが多いのだ。だから十分な品質で手のデータを学習できていないのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 14,
    "sceneTitle": "手が描けない3つの理由"
  },
  {
    "startTimeSec": 704.0679999999999,
    "startFrame": 21122,
    "durationSec": 3.936,
    "durationFrames": 118,
    "speaker": "めたん",
    "text": "確かに、写真って顔はアップで写っても手はそうでもないですわね。",
    "speakerColor": "#d6336c",
    "sceneId": 14,
    "sceneTitle": "手が描けない3つの理由"
  },
  {
    "startTimeSec": 708.3039999999999,
    "startFrame": 21249,
    "durationSec": 7.370666666666667,
    "durationFrames": 221,
    "speaker": "ずんだもん",
    "text": "そして3つ目、これが一番根本的な理由なのだ。AIは指は5本っていう知識を持っていないのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 14,
    "sceneTitle": "手が描けない3つの理由"
  },
  {
    "startTimeSec": 716.2,
    "startFrame": 21486,
    "durationSec": 4.384,
    "durationFrames": 132,
    "speaker": "めたん",
    "text": "え?知らないんですの?人間なら当たり前のことですのに。",
    "speakerColor": "#d6336c",
    "sceneId": 15,
    "sceneTitle": "コラージュ誤解"
  },
  {
    "startTimeSec": 720.884,
    "startFrame": 21627,
    "durationSec": 19.488,
    "durationFrames": 585,
    "speaker": "ずんだもん",
    "text": "そうなのだ。拡散モデルは画像のパターンの統計的な傾向を学んでいるだけで、手には指が5本あるとか関節はこの方向にしか曲がらないという構造的な知識は一切持っていないのだ。だからこのあたりは指っぽいパターンだな程度の理解で描いてしまうから、時々変な形が出てくるのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 15,
    "sceneTitle": "コラージュ誤解"
  },
  {
    "startTimeSec": 740.672,
    "startFrame": 22220,
    "durationSec": 9.834666666666667,
    "durationFrames": 295,
    "speaker": "めたん",
    "text": "パターンは知ってるけどルールは知らない、ということですのね。そういえば、AIはネット上の画像を切り貼りしているっていう話も聞きますけど、それは本当ですの?",
    "speakerColor": "#d6336c",
    "sceneId": 15,
    "sceneTitle": "コラージュ誤解"
  },
  {
    "startTimeSec": 750.8066666666667,
    "startFrame": 22524,
    "durationSec": 20.78933333333333,
    "durationFrames": 624,
    "speaker": "ずんだもん",
    "text": "それは完全な誤解なのだ。拡散モデルは個別の画像を記憶しているわけじゃないのだ。何百万枚もの画像から画像っぽさの確率分布を学んでいるのだ。たとえて言うなら、何千冊もの料理本を読んだ人が、レシピを暗記しているんじゃなくて、料理のパターンを身につけてオリジナル料理を作るようなものなのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 15,
    "sceneTitle": "コラージュ誤解"
  },
  {
    "startTimeSec": 771.8960000000001,
    "startFrame": 23157,
    "durationSec": 2.7626666666666666,
    "durationFrames": 83,
    "speaker": "めたん",
    "text": "なるほど。コラージュでもコピーでもないんですのね。",
    "speakerColor": "#d6336c",
    "sceneId": 15,
    "sceneTitle": "コラージュ誤解"
  },
  {
    "startTimeSec": 774.9586666666668,
    "startFrame": 23249,
    "durationSec": 17.877333333333333,
    "durationFrames": 536,
    "speaker": "ずんだもん",
    "text": "ただし、学習データに使われた画像の著作権をめぐっては大きな議論が起きているのだ。写真素材の大手ゲッティイメージズがスタビリティAIを著作権侵害で訴えた事例もあるし、多くのイラストレーターが自分の作品が無断で学習に使われたと抗議しているのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 15,
    "sceneTitle": "コラージュ誤解"
  },
  {
    "startTimeSec": 793.3000000000001,
    "startFrame": 23799,
    "durationSec": 5.461333333333333,
    "durationFrames": 164,
    "speaker": "めたん",
    "text": "技術的にはコピーじゃなくても、学習に使ったこと自体が問題になるケースがあるんですのね。",
    "speakerColor": "#d6336c",
    "sceneId": 16,
    "sceneTitle": "著作権の議論"
  },
  {
    "startTimeSec": 799.0613333333334,
    "startFrame": 23972,
    "durationSec": 19.136,
    "durationFrames": 574,
    "speaker": "ずんだもん",
    "text": "そうなのだ。分布を学んでいるだけだから問題ないという主張と、許可なく学習すること自体が権利侵害だという主張がぶつかっていて、今まさに世界中で法的な判断が進んでいるところなのだ。技術の仕組みを正しく理解した上で、こうした問題にも目を向けていくことが大事なのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 16,
    "sceneTitle": "著作権の議論"
  },
  {
    "startTimeSec": 818.7,
    "startFrame": 24561,
    "durationSec": 13.706666666666667,
    "durationFrames": 411,
    "speaker": "ずんだもん",
    "text": "さて、今日の話をまとめるのだ。拡散モデルのポイントは3つなのだ。1つ目、拡散モデルはきれいな画像にノイズを加えて壊す、逆にノイズを取り除いて復元するの2段階で動いていること。",
    "speakerColor": "#22c55e",
    "sceneId": 17,
    "sceneTitle": "まとめ3ポイント"
  },
  {
    "startTimeSec": 832.7066666666667,
    "startFrame": 24981,
    "durationSec": 2.4106666666666667,
    "durationFrames": 72,
    "speaker": "めたん",
    "text": "フォワードプロセスとリバースプロセスですわね。",
    "speakerColor": "#d6336c",
    "sceneId": 17,
    "sceneTitle": "まとめ3ポイント"
  },
  {
    "startTimeSec": 835.4173333333333,
    "startFrame": 25063,
    "durationSec": 13.653333333333334,
    "durationFrames": 410,
    "speaker": "ずんだもん",
    "text": "2つ目、Stable Diffusionでは画像を64分の1に圧縮してからノイズ除去を行い、テキストはクリップでベクトルに変換してユーネットに指示を出していること。",
    "speakerColor": "#22c55e",
    "sceneId": 17,
    "sceneTitle": "まとめ3ポイント"
  },
  {
    "startTimeSec": 849.3706666666667,
    "startFrame": 25481,
    "durationSec": 2.421333333333333,
    "durationFrames": 73,
    "speaker": "めたん",
    "text": "だから一般のパソコンでも動くんですわね。",
    "speakerColor": "#d6336c",
    "sceneId": 17,
    "sceneTitle": "まとめ3ポイント"
  },
  {
    "startTimeSec": 852.092,
    "startFrame": 25563,
    "durationSec": 12.949333333333334,
    "durationFrames": 388,
    "speaker": "ずんだもん",
    "text": "3つ目、AIは画像を描いているのではなく、ノイズの中から統計的なパターンを見つけ出しているということ。だから手の描画が苦手だったり、構造的な理解はしていなかったりするのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 17,
    "sceneTitle": "まとめ3ポイント"
  },
  {
    "startTimeSec": 865.5,
    "startFrame": 25965,
    "durationSec": 4.8,
    "durationFrames": 144,
    "speaker": "めたん",
    "text": "動画の最初に言っていた砂嵐から始まるっていうのは、こういう意味だったんですのね。",
    "speakerColor": "#d6336c",
    "sceneId": 18,
    "sceneTitle": "応用展開"
  },
  {
    "startTimeSec": 870.6,
    "startFrame": 26118,
    "durationSec": 22.272,
    "durationFrames": 668,
    "speaker": "ずんだもん",
    "text": "そうなのだ。AIが生成する画像は、文字通り砂嵐から始まっているのだ。そしてこの拡散モデルの技術は、今や画像だけにとどまらないのだ。OpenAIのソラはテキストから動画を生成するし、ドリームフュージョンはテキストから3Dモデルを作るし、音声合成にも拡散モデルが使われ始めているのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 18,
    "sceneTitle": "応用展開"
  },
  {
    "startTimeSec": 893.172,
    "startFrame": 26795,
    "durationSec": 5.770666666666667,
    "durationFrames": 173,
    "speaker": "めたん",
    "text": "画像だけじゃなく、動画も3Dも音声も全部同じ原理から来てるんですのね。すごいですわ。",
    "speakerColor": "#d6336c",
    "sceneId": 18,
    "sceneTitle": "応用展開"
  },
  {
    "startTimeSec": 899.2426666666667,
    "startFrame": 26977,
    "durationSec": 12.928,
    "durationFrames": 388,
    "speaker": "ずんだもん",
    "text": "しかもStable Diffusionはオープンソースで公開されていて、誰でも無料で使えるのだ。これによって画像生成AIが一気に世界中に広まったのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 18,
    "sceneTitle": "応用展開"
  },
  {
    "startTimeSec": 912.4706666666666,
    "startFrame": 27374,
    "durationSec": 1.92,
    "durationFrames": 58,
    "speaker": "めたん",
    "text": "技術の民主化ってやつですわね。",
    "speakerColor": "#d6336c",
    "sceneId": 18,
    "sceneTitle": "応用展開"
  },
  {
    "startTimeSec": 914.6906666666666,
    "startFrame": 27441,
    "durationSec": 11.146666666666667,
    "durationFrames": 334,
    "speaker": "ずんだもん",
    "text": "今日の動画で、画像生成AIの中身がブラックボックスじゃなくなったと思うのだ。なんかすごいじゃなくてこうやって動いてたのかって思えたなら、この動画は成功なのだ。",
    "speakerColor": "#22c55e",
    "sceneId": 18,
    "sceneTitle": "応用展開"
  },
  {
    "startTimeSec": 926.1373333333333,
    "startFrame": 27784,
    "durationSec": 3.3706666666666667,
    "durationFrames": 101,
    "speaker": "めたん",
    "text": "今日もとっても勉強になりましたわ。ありがとうございました!",
    "speakerColor": "#d6336c",
    "sceneId": 18,
    "sceneTitle": "応用展開"
  },
  {
    "startTimeSec": 929.808,
    "startFrame": 27894,
    "durationSec": 3.1466666666666665,
    "durationFrames": 94,
    "speaker": "ずんだもん",
    "text": "こちらこそなのだ。次回もお楽しみになのだ!",
    "speakerColor": "#22c55e",
    "sceneId": 18,
    "sceneTitle": "応用展開"
  }
];
