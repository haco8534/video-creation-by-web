# リサーチチェックポイント：反論・例外・誤解されやすい点

## 収集ファクト一覧

| # | ファクト | 信頼度 | 出典 |
|---|---------|--------|------|
| 1 | 拡散モデルはGANに比べて推論（画像生成）が大幅に遅い。DDPMは元々1000ステップ必要で、DDIMでも50ステップ程度。GANは1回のフォワードパスで生成可能 | 🟢高 | 複数のベンチマーク比較論文 |
| 2 | 拡散モデルは手の描画が苦手。指が6本になる、関節が不自然に曲がるなどの「ハルシネーション」が頻繁に発生する。原因は(1)手の解剖学的複雑さ、(2)学習データの偏り、(3)AIが解剖学的一貫性を理解していない | 🟢高 | 多数のユーザー報告・研究論文 |
| 3 | 「AIが絵を描いている」「学習データからコラージュしている」は誤解。実際はデータ分布を学習しており、個別の画像を記憶・切り貼りしているわけではない | 🟢高 | 技術解説・研究者の説明 |
| 4 | 訓練データの著作権問題が深刻。多くのモデルはインターネットからスクレイピングした無許諾の画像で訓練されており、アーティストの権利侵害が指摘されている | 🟢高 | Getty Images vs Stability AI 訴訟、多数の報道 |
| 5 | 訓練データに含まれるバイアスが生成画像にも反映される。例えば、暗い肌色の正確な表現が困難、特定の人種とネガティブな画像が結びつくなどの問題 | 🟢高 | 研究論文・Milvus技術記事 |
| 6 | 高解像度画像の生成にはVRAMと計算リソースが大量に必要。トレーニングには数週間のGPU時間と大規模データセットが必要 | 🟢高 | 技術報告・ベンチマーク |
| 7 | 拡散モデルはテキストプロンプトの組み合わせ（compositionality）が苦手。複数の被写体や複雑な配置を正確に生成することが難しい（例：「赤い帽子をかぶった猫と青い服を着た犬」で属性が混ざる「Prompt bleed」） | 🟡中 | Scale.com研究レポート、Reddit報告 |
| 8 | ディープフェイクやフェイクニュースへの悪用リスク。リアルな偽画像を容易に生成できることで、社会的な信頼が損なわれる懸念 | 🟢高 | 複数のセキュリティ・倫理研究 |
| 9 | GANの方がリアルタイムアプリケーションには適している。学習済みGANは1回のフォワードパスで瞬時に生成可能で、動画のリアルタイム加工などではGANが依然として有利 | 🟡中 | 技術比較記事 |
| 10 | 「プロンプトだけで全てが決まる」は誤解。実際にはノイズの初期値（シード）、サンプリング手法（DDPM/DDIM/DPM-Solver等）、CFGスケール、ステップ数などのパラメータが生成結果に大きく影響する | 🟡中 | 技術コミュニティの知見 |
| 11 | 拡散モデルは確率的性質を持つため、同じプロンプトでも毎回異なる画像が生成される（シードを固定しない場合）。これは利点にも欠点にもなりうる | 🟡中 | 技術解説 |

## まとめ・所感

反論・限界として台本で使えるポイント：

1. **速度の問題**：「50ステップでも遅い。GANは1回で済む」→ なぜ拡散モデルが主流になったかの対比に使える
2. **手の問題**：視聴者にとって最も身近な「AIのバグ」。なぜ起きるかを解説するとメカニズムの理解が深まる
3. **コラージュ誤解の解消**：「画像のコピペではなく、分布の学習」→ 中盤の意外性に使える
4. **著作権・倫理問題**：テーマの社会的文脈として重要。深入りしすぎないが触れるべき
5. **Prompt bleed**：プロンプトの限界を示す具体例として面白い
