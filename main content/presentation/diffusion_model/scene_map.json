{
    "voicevox_url": "http://localhost:50021",
    "speakers": {
        "ずんだもん": 3,
        "めたん": 2
    },
    "speed_scale": 1.15,
    "inter_line_silence": 0.3,
    "scene_end_padding": 0.5,
    "scenes": [
        {
            "id": 0,
            "title": "タイトルカード",
            "hold_sec": 4,
            "lines": []
        },
        {
            "id": 1,
            "title": "AIは描くのではなく見つけ出す",
            "hold_sec": 0,
            "lines": [
                {
                    "speaker": "めたん",
                    "text": "今日はどんなお話ですの?"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "今日は、画像生成AIがどうやって絵を作っているのか、その仕組みを全部解説するのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "Stable DiffusionとかMidjourneyとか、最近すごいですわよね。テキストを入れるだけで絵が出てくるんですもの。"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "そうなのだ。でもここで一つ質問なのだ。AIが描いた絵って、実は砂嵐のテレビから始まってるって知ってたのだ?"
                },
                {
                    "speaker": "めたん",
                    "text": "え?砂嵐?あの地上波が終わった後に出てくるザーッていうやつですの?"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "そうなのだ。多くの人はAIが人間みたいに筆を動かして絵を描いているとか、ネット上の画像を切り貼りしていると思っているのだ。でも実際は全然違うのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "じゃあ何をしてるんですの?"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "AIは、完全にランダムなノイズ、つまり砂嵐みたいな画像の中から、少しずつパターンを見つけ出して、画像を浮かび上がらせているのだ。描いているんじゃなくて、見つけ出しているのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "砂嵐から画像を見つけ出す、にわかには信じがたいですわね。"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "不思議に聞こえるだろう?でもこれは比喩じゃなくて本当にそうなのだ。今日はその仕組みを拡散モデルの原理から全部説明するのだ。この動画を見終わる頃には、画像生成AIの中で何が起きているのか、全部わかるようになるのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "楽しみですわ!早く教えてくださいな。"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "もちろんなのだ。でもその前に、ちょっとだけ歴史の話をさせてほしいのだ。そもそも画像を自動で作るAIってのは拡散モデルが最初じゃないのだ。"
                }
            ]
        },
        {
            "id": 2,
            "title": "画像生成AIの歴史",
            "hold_sec": 0,
            "lines": [
                {
                    "speaker": "ずんだもん",
                    "text": "画像を自動で作り出すAIの研究は、ざっくり3つの世代に分けられるのだ。最初は2013年のブイエーイー、次が2014年のガン、そして今の主流が2020年に実用化された拡散モデルなのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "ガンって聞いたことありますわ。一時期話題になってましたわよね。"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "そうなのだ。ガンは約6年間、画像生成AIの王様だったのだ。"
                }
            ]
        },
        {
            "id": 3,
            "title": "GAN vs 拡散モデル",
            "hold_sec": 0,
            "lines": [
                {
                    "speaker": "ずんだもん",
                    "text": "ガンの仕組みを簡単にたとえると、偽造者と鑑定士の対決なのだ。偽造者が偽物の画像を作って、鑑定士がこれは偽物だぞと見破ろうとする。この対決を何十万回も繰り返すことで、偽造者の腕がどんどん上がって、最終的には本物そっくりの画像が作れるようになるのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "面白い仕組みですわね。でもそれが主流じゃなくなったのはなぜですの?"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "対決形式には大きな弱点があったのだ。偽造者と鑑定士のバランスを取るのがものすごく難しくて、片方が強くなりすぎるとすぐに学習が破綻するのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "どちらかが圧勝してしまうと成り立たないんですのね。"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "そうなのだ。さらにモード崩壊って言って、偽造者がこの手の画像なら鑑定士を騙せるって学習してしまうと、同じような画像ばかり生成してしまう問題もあったのだ。"
                }
            ]
        },
        {
            "id": 4,
            "title": "拡散モデルが主流になった理由",
            "hold_sec": 0,
            "lines": [
                {
                    "speaker": "めたん",
                    "text": "なるほど、それは困りますわね。で、拡散モデルはどう違うんですの?"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "拡散モデルは対決なんか一切しないのだ。やっていることはもっとシンプルで、画像に加えられたノイズを予測するという1つのタスクだけを学習するのだ。対戦相手がいないから、バランス調整の問題が起きない。だから学習が非常に安定していて、多様な画像を生成できるのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "対決じゃなくて、お掃除みたいな感じですのね。汚れを見つけて取り除くだけ。"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "まさにそうなのだ。イメージとしてはお掃除ロボットに近いのだ。で、この拡散モデルが具体的にどんな仕組みで動いているのか、ここからが本題なのだ。"
                }
            ]
        },
        {
            "id": 5,
            "title": "拡散モデルの基本原理タイトル",
            "hold_sec": 3,
            "lines": []
        },
        {
            "id": 6,
            "title": "Forward Process",
            "hold_sec": 0,
            "lines": [
                {
                    "speaker": "めたん",
                    "text": "いよいよ本題ですわね。拡散モデルって、そもそもどういう仕組みなんですの?"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "拡散モデルの原理は、実は物理学から来ているのだ。2015年にスタンフォード大学のソールディクスタインっていう研究者が、非平衡熱力学っていう物理の分野からヒントを得て考案したのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "非平衡熱力学、難しそうですわね。"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "言葉は難しいけど、原理はシンプルなのだ。水にインクを一滴垂らすと、最初はくっきりした色の塊なのに、時間が経つとだんだん広がって、最終的には全体が均一にぼんやりしてしまうのだ。これが物理学でいう拡散で、拡散モデルの名前の由来なのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "なるほど。インクが広がるイメージですのね。それが画像生成と何の関係がありますの?"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "拡散モデルでは、きれいな画像にちょっとずつノイズを加えていくのだ。ステップ1では画像がほんの少しだけザラザラする。ステップ2ではもう少しザラザラになる。これを何百回も繰り返すと、最終的には元の画像が何だったか全くわからない、完全なノイズ、つまり砂嵐になるのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "わざと画像を壊していくんですの?何のためにそんなことを?"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "いい質問なのだ。この壊す過程はフォワードプロセスって呼ばれていて、ここではAIの学習は何も行われないのだ。ただ機械的にノイズを乗せていくだけなのだ。大事なのはこの次なのだ。"
                }
            ]
        },
        {
            "id": 7,
            "title": "Reverse Process",
            "hold_sec": 0,
            "lines": [
                {
                    "speaker": "ずんだもん",
                    "text": "今度は逆に、完全なノイズの状態からスタートして、少しずつノイズを取り除いていくのだ。ステップ1ではうっすらと輪郭が見え始める。ステップ2ではもう少し形がはっきりしてくる。これを繰り返していくと、最終的にはきれいな画像が浮かび上がってくるのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "壊す、戻すってことですのね。まるで彫刻みたいですわ。大理石の塊から像を掘り出すような。"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "おっ、いいたとえなのだ。実際そのイメージに近いのだ。で、ここで重要なのはAIはどうやって戻し方を知るのかなのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "そうですわね。壊すのは簡単でも、戻すのは難しそうですわ。"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "ここがポイントなのだ。AIに大量の画像で壊す、戻すの練習をさせるのだ。何百万枚もの画像に対して、いろんな段階でノイズを加えて、そのノイズを取り除く練習を繰り返すのだ。猫の画像でも風景の画像でも、ありとあらゆる画像で練習するのだ。"
                }
            ]
        },
        {
            "id": 8,
            "title": "ノイズε予測",
            "hold_sec": 0,
            "lines": [
                {
                    "speaker": "めたん",
                    "text": "でもそれって膨大な計算になりませんの?"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "実はここに美しい発見があるのだ。2020年にジョナサンホーらの研究チームが発表したDDPMっていう論文で、学習の目標をものすごくシンプルにできることが示されたのだ。やるべきことはたった1つ、この画像にどんなノイズが加えられたかを予測するだけなのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "ノイズを予測するだけ!?それだけであんなすごい画像が作れるんですの?"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "そうなのだ。数学的にはイプシロンって呼ばれるノイズ成分を予測するだけで、結果的に画像全体を復元できることが証明されたのだ。画像を丸ごと予測するんじゃなくて、このステップでどれだけ汚れが乗ったかだけ当てればいいのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "シンプルだけど奥が深いですわね。"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "このシンプルさこそが、拡散モデルの安定した学習を可能にしている鍵なのだ。ガンみたいに敵同士を戦わせる必要がないから、学習が途中で壊れにくいのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "なるほど、原理はよくわかりましたわ。でも実際のStable Diffusionとかって、もうちょっと複雑なんじゃありませんの?"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "いいところに気づいたのだ。実は、今の原理をそのまま使うと計算コストが大きすぎるのだ。512かける512の画像で直接ノイズ除去をすると、とてもじゃないけど一般のパソコンでは動かないのだ。だから実際の製品にはいくつもの天才的な工夫が加えられているのだ。"
                }
            ]
        },
        {
            "id": 9,
            "title": "Stable Diffusionの全体構造",
            "hold_sec": 0,
            "lines": [
                {
                    "speaker": "ずんだもん",
                    "text": "Stable Diffusionの中身には、大きく分けて3つの部品があるのだ。まずブイエーイーっていう圧縮装置、次にユーネットっていうノイズ除去エンジン、そしてまたブイエーイーの復元装置なのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "3つの部品が連携してるんですのね。まず最初のブイエーイーって何をするんですの?"
                }
            ]
        },
        {
            "id": 10,
            "title": "VAE圧縮 64分の1",
            "hold_sec": 0,
            "lines": [
                {
                    "speaker": "ずんだもん",
                    "text": "ブイエーイーは画像を圧縮する役割なのだ。例えば512かける512ピクセルの画像があったとするだろう。これは約78万ピクセルもあるのだ。直接ノイズ除去しようとすると、とんでもない計算量が必要になるのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "78万ピクセル、確かに多いですわね。"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "だからブイエーイーが画像を潜在空間っていう小さな世界に圧縮するのだ。具体的には64かける64まで縮小するのだ。データ量にして約64分の1なのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "64分の1ですの!?そんなに小さくして大丈夫なんですの?"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "ブイエーイーは賢いのだ。ただ画像を縮小するんじゃなくて、画像の本質的な特徴、つまり形や色の傾向、テクスチャの情報だけを保存するのだ。いわば画像のエッセンスだけ取り出すイメージなのだ。細かいピクセル情報は捨てるけど、意味のある情報はちゃんと残すのだ。"
                }
            ]
        },
        {
            "id": 11,
            "title": "CLIP + Cross-Attention",
            "hold_sec": 0,
            "lines": [
                {
                    "speaker": "ずんだもん",
                    "text": "次がユーネットなのだ。これがノイズ除去の本体で、名前の通りU字の形をしたニューラルネットワークなのだ。圧縮された画像のノイズを予測して取り除くのだ。ここで面白いのは、ユーネットにはテキストの情報も入ってくるのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "テキストの情報?プロンプトのことですわね。どうやって文字の情報を画像生成に使っているんですの?"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "ユーザーが入力したプロンプト、例えば夕焼けの海辺を歩く猫は、まずクリップっていう別のAIがテキストを数値のベクトルに変換するのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "言葉を数字に変えるんですのね。"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "そうなのだ。そしてそのベクトルが、ユーネットの中にあるクロスアテンションっていう仕組みを通じて、こういう雰囲気の画像にしてくれという指示を出すのだ。ノイズを除去するときに、テキストの意味を参考にしながら方向性を決める、いわばガイド役なのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "テキストがAIへのナビゲーターになるんですのね。砂嵐の中から猫っぽいものを探し出すためのヒントを与えてくれる。"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "まさにそうなのだ。さらにクラシファイアフリーガイダンスっていうテクニックで、プロンプトにどれくらい忠実に従うかも調整できるのだ。"
                }
            ]
        },
        {
            "id": 12,
            "title": "DDIM高速化",
            "hold_sec": 0,
            "lines": [
                {
                    "speaker": "ずんだもん",
                    "text": "次に速度の工夫なのだ。元々の拡散モデルは、ノイズを除去するのに1000ステップも必要だったのだ。1枚の画像を作るのに1000回もAIを動かさないといけないのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "それはさすがに遅すぎますわね。"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "だからDDIMっていう高速化手法が開発されたのだ。これは1ステップずつ地道に進む代わりに、大きくジャンプしながらノイズを除去する方法なのだ。これを使うと、1000ステップを約50ステップまで減らせるのだ。約20倍の高速化で、しかも画質はほとんど落ちないのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "1000が50に!それはすごい進歩ですわね。"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "こうした工夫、ブイエーイーによる圧縮、ユーネットとクロスアテンション、そしてDDIMによる高速化が全部組み合わさったおかげで、Stable Diffusionは一般の人のパソコンでも動くようになったのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "すごい技術の積み重ねですわね。"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "でもね、そんな拡散モデルにも、どうしても苦手なことがあるのだ。"
                }
            ]
        },
        {
            "id": 13,
            "title": "AIの限界と誤解タイトル",
            "hold_sec": 3,
            "lines": []
        },
        {
            "id": 14,
            "title": "手が描けない3つの理由",
            "hold_sec": 0,
            "lines": [
                {
                    "speaker": "めたん",
                    "text": "苦手なこと?そういえばAIが描いた絵って、手がおかしいことが多いですわよね。指が6本あったり、変な方向に曲がってたり。"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "まさにそれなのだ。実はAIが手を描くのが苦手なのには、ちゃんとした理由があるのだ。"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "理由は大きく3つあるのだ。1つ目は、手の構造がめちゃくちゃ複雑だってこと。骨だけでも27本あって、関節は指だけで14個。指の曲がり方の組み合わせが膨大すぎるのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "確かに、手って体の中でも特に複雑な部位ですわよね。"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "2つ目は、学習データの問題なのだ。ネット上の画像って、手が小さく写っていたり、ぼやけていたり、物を持って隠れていたりすることが多いのだ。だから十分な品質で手のデータを学習できていないのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "確かに、写真って顔はアップで写っても手はそうでもないですわね。"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "そして3つ目、これが一番根本的な理由なのだ。AIは指は5本っていう知識を持っていないのだ。"
                }
            ]
        },
        {
            "id": 15,
            "title": "コラージュ誤解",
            "hold_sec": 0,
            "lines": [
                {
                    "speaker": "めたん",
                    "text": "え?知らないんですの?人間なら当たり前のことですのに。"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "そうなのだ。拡散モデルは画像のパターンの統計的な傾向を学んでいるだけで、手には指が5本あるとか関節はこの方向にしか曲がらないという構造的な知識は一切持っていないのだ。だからこのあたりは指っぽいパターンだな程度の理解で描いてしまうから、時々変な形が出てくるのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "パターンは知ってるけどルールは知らない、ということですのね。そういえば、AIはネット上の画像を切り貼りしているっていう話も聞きますけど、それは本当ですの?"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "それは完全な誤解なのだ。拡散モデルは個別の画像を記憶しているわけじゃないのだ。何百万枚もの画像から画像っぽさの確率分布を学んでいるのだ。たとえて言うなら、何千冊もの料理本を読んだ人が、レシピを暗記しているんじゃなくて、料理のパターンを身につけてオリジナル料理を作るようなものなのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "なるほど。コラージュでもコピーでもないんですのね。"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "ただし、学習データに使われた画像の著作権をめぐっては大きな議論が起きているのだ。写真素材の大手ゲッティイメージズがスタビリティAIを著作権侵害で訴えた事例もあるし、多くのイラストレーターが自分の作品が無断で学習に使われたと抗議しているのだ。"
                }
            ]
        },
        {
            "id": 16,
            "title": "著作権の議論",
            "hold_sec": 0,
            "lines": [
                {
                    "speaker": "めたん",
                    "text": "技術的にはコピーじゃなくても、学習に使ったこと自体が問題になるケースがあるんですのね。"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "そうなのだ。分布を学んでいるだけだから問題ないという主張と、許可なく学習すること自体が権利侵害だという主張がぶつかっていて、今まさに世界中で法的な判断が進んでいるところなのだ。技術の仕組みを正しく理解した上で、こうした問題にも目を向けていくことが大事なのだ。"
                }
            ]
        },
        {
            "id": 17,
            "title": "まとめ3ポイント",
            "hold_sec": 0,
            "lines": [
                {
                    "speaker": "ずんだもん",
                    "text": "さて、今日の話をまとめるのだ。拡散モデルのポイントは3つなのだ。1つ目、拡散モデルはきれいな画像にノイズを加えて壊す、逆にノイズを取り除いて復元するの2段階で動いていること。"
                },
                {
                    "speaker": "めたん",
                    "text": "フォワードプロセスとリバースプロセスですわね。"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "2つ目、Stable Diffusionでは画像を64分の1に圧縮してからノイズ除去を行い、テキストはクリップでベクトルに変換してユーネットに指示を出していること。"
                },
                {
                    "speaker": "めたん",
                    "text": "だから一般のパソコンでも動くんですわね。"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "3つ目、AIは画像を描いているのではなく、ノイズの中から統計的なパターンを見つけ出しているということ。だから手の描画が苦手だったり、構造的な理解はしていなかったりするのだ。"
                }
            ]
        },
        {
            "id": 18,
            "title": "応用展開",
            "hold_sec": 0,
            "lines": [
                {
                    "speaker": "めたん",
                    "text": "動画の最初に言っていた砂嵐から始まるっていうのは、こういう意味だったんですのね。"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "そうなのだ。AIが生成する画像は、文字通り砂嵐から始まっているのだ。そしてこの拡散モデルの技術は、今や画像だけにとどまらないのだ。OpenAIのソラはテキストから動画を生成するし、ドリームフュージョンはテキストから3Dモデルを作るし、音声合成にも拡散モデルが使われ始めているのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "画像だけじゃなく、動画も3Dも音声も全部同じ原理から来てるんですのね。すごいですわ。"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "しかもStable Diffusionはオープンソースで公開されていて、誰でも無料で使えるのだ。これによって画像生成AIが一気に世界中に広まったのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "技術の民主化ってやつですわね。"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "今日の動画で、画像生成AIの中身がブラックボックスじゃなくなったと思うのだ。なんかすごいじゃなくてこうやって動いてたのかって思えたなら、この動画は成功なのだ。"
                },
                {
                    "speaker": "めたん",
                    "text": "今日もとっても勉強になりましたわ。ありがとうございました!"
                },
                {
                    "speaker": "ずんだもん",
                    "text": "こちらこそなのだ。次回もお楽しみになのだ!"
                }
            ]
        }
    ]
}