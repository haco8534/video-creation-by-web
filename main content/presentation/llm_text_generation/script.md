# 【台本】LLMが文章を生成する仕組み：入力から出力までの完全解剖

- 作成日: 2026-02-23
- 目標尺: 約20分
- コアメッセージ: LLMは「言語を理解している」のではなく、膨大なテキストから学んだ確率的なパターンに基づいて「次に来る最も尤もらしい単語」を一つずつ予測し、連鎖させることで文章を生成している。
- 冒頭フック: 「ChatGPTって、実は文章の意味を1ミリも理解していないって知ってました？」
- 登場人物: ずんだもん（解説）、めたん（聞き役）
- セリフ総文字数: 約6400文字（目標：6,000〜7,000文字）

---

## 【Block 1：オープニング：「AIは文章を理解していない？」】
<!-- 推定時間：2分 / 目標文字数：800文字 -->

めたん：ねえ、ずんだもん。最近仕事でもプライベートでもChatGPTをよく使うんだけど、あれって本当に何でも知ってて賢いよね。言葉の裏のニュアンスまで汲み取ってくれるし、まるで中にすごく物知りな人間が入ってるんじゃないかって思っちゃうわ。

ずんだもん：ふふん、AIが人間みたいに言葉を理解しているって、みんなそう思っているのだ。でもめたん、実はここで衝撃的な事実を教えるのだ。

めたん：え、なに？ 改まって。

ずんだもん：ChatGPTをはじめとする大規模言語モデル、いわゆるLLMは、僕たちが入力した文章の意味を、実は「1ミリも理解していない」のだ！

めたん：ええっ！？ 嘘でしょ！？ だって「今日の東京の天気はどう？」って聞いたら、ちゃんと「晴れです。傘はいりませんよ」なんて気の利いたことまで答えてくれるじゃない。意味がわかってないのに、どうしてそんな完璧なコミュニケーションができるの？

ずんだもん：そこが現代のAIの最も面白くて、恐ろしいところなのだ！ 実はAIの界隈では、LLMのことを「確率的オウム」なんて呼んだりする批判もあるくらいなのだ。意味も分からず、ただ確率の高い言葉をオウム返ししているだけだ、っていう皮肉なのだ。少し昔にあった「中国語の部屋」という思考実験と同じで、ただ中のマニュアル通りに記号を並び替えているだけで、意味はわかってないんじゃないか、と言われているのだ。

めたん：オウム返し……？ でも、ただのオウム返しには見えないわよ。じゃあ一体、AIの中で何が起きているの？

ずんだもん：それを今から解き明かすのだ！ 今日は、めたんがパソコンやスマホで「東京の天気は？」と文字を入力してから、AIが回答の文字を出力するまでの全ステップを、初心者向けだからといってごまかさずに、最初から最後まで一直線に追っていくのだ。

めたん：おおー！ 入力した言葉がどうやって処理されて、どうやって答えになって返ってくるのか。データの流れが目で見えるようになるってことね！

ずんだもん：その通りなのだ。これを見終わる頃には、AIが「まったく意味を理解していないのに、どうしてあんなに賢く見えるのか」その本当のからくりが完全に腑に落ちるはずなのだ！

めたん：楽しみ！ それじゃあ、さっそく教えてちょうだい！

ずんだもん：それでは、AIの脳内に飛び込んでみるのだ。でもその前に、文字はそのままではコンピュータには読めないのだ……。

---

## 【Block 2：ステップ①〜②：トークン化と埋め込み】
<!-- 推定時間：3分 / 目標文字数：1,000文字 -->

ずんだもん：それじゃあ、まずは第一のステップ「入力」から始まるのだ。めたんが「東京の天気は？」と入力して送信ボタンを押した直後を想像してほしいのだ。

めたん：うん。文字がインターネットを通って、AIのサーバーに届くのよね。

ずんだもん：そうなのだ。でも、AIの脳みそとなっているコンピュータは、僕たちが使う「日本語の文字」をそのまま読めるわけじゃないのだ。コンピュータが理解できるのは「数字」だけなのだ。

めたん：あ、それは聞いたことあるわ。0と1の世界ってやつよね。

ずんだもん：なのだ。だから、まずは文章を数字に変えるための準備作業が必要なのだ。これを「トークン化」と呼ぶのだ。

めたん：トークン化？ なんだか仮想通貨みたいな名前ね。

ずんだもん：英語で「しるし」とか「断片」って意味なのだ。文章を、AIが扱いやすい小さな「レゴブロック」に分解する作業だと思えばいいのだ。例えば「東京の天気は？」という文章なら、「東京」「の」「天気」「は」「？」みたいに切り分けるのだ。

めたん：なるほど。単語ごとにバラバラにするのね。

ずんだもん：ただ、単語で綺麗に分かれるとは限らなくてね。よく使われる文字の並びごとに区切る「BPE（Byte Pair Encoding）」っていう賢い仕組みが使われているのだ。ともかく、こうして切り分けた1つ1つのブロックを「トークン」と呼ぶのだ。そして、この「天気」といったトークンに、それぞれ背番号みたいな「ID番号」を割り振るのだ。

めたん：ふむふむ。「東京」は105番、「の」は12番、みたいに辞書の番号に置き換えるのね。これならコンピュータも読めそうね。

ずんだもん：でも、まだこれだけじゃ甘いのだ。

めたん：えっ、番号にするだけじゃダメなの？

ずんだもん：ただの連番の背番号だと、1番の言葉と2番の言葉に意味の繋がりがあるとは限らないのだ。AIに言葉の「関係性」を教えるための魔法、第二のステップ「埋め込み」、英語で「Word Embedding（ワード・エンベディング）」を行うのだ！

めたん：埋め込み？ どこに何を埋め込むのよ。

ずんだもん：さっきのトークンを、膨大な次元を持つ「空間」の中に埋め込むのだ。例えば、空間の座標を考えてほしいのだ。(x, y, z)みたいな。これを数千次元という長い数字のリストに変換するのだ。

めたん：数千次元！？ 三次元までしか想像できないわよ！

ずんだもん：僕たちには想像できない空間だけど、コンピュータには計算できるのだ。この空間のすごいところは、意味が似ている言葉は、空間の中でも近い座標に配置されるってことなのだ。「犬」と「猫」は近い場所、「犬」と「消しゴム」は遠い場所、という具合に、言葉同士の距離や関係性を座標データとして表すのだ。

めたん：へええ！ つまり、ただの連番の背番号から、言葉の「意味の近さ」を表す長〜い数字のリストにパワーアップさせるってことね！

ずんだもん：その通りなのだ！ さらに文章の「並び順」の情報も付加されるのだ。こうして、僕たちの文章は、意味と順番を持った巨大な数字の集まりに変身したのだ。そして「住所」が決まった数字のブロックたちは、次にいよいよ、かつてない革命をもたらしたAIの本当の心臓部へと送り込まれるのだ……！

---

## 【Block 3：ステップ③：Attention ──「文脈を読む」仕組み】
<!-- 推定時間：5分 / 目標文字数：1,600文字 -->

めたん：いよいよ心臓部ね！ ゴクリ……。

ずんだもん：ここからが第三のステップ。現代の生成AIを劇的に賢くした大発明、「Transformer（トランスフォーマー）」というネットワークの内部に入っていくのだ。

めたん：トランスフォーマー！ 映画みたいな名前ね。なんかガシャンガシャン変形しそう。

ずんだもん：2017年にGoogleの研究者たちが発表した「Attention Is All You Need」っていう伝説の論文で提案された仕組みなのだ。実は今のChatGPTもGeminiも、ぜーんぶこの1本の論文から生まれたと言っていいのだ！

めたん：ええっ！ 2017年のたった1つの発明が、今のAIブームのまさに原点になっているの！？ すごすぎるわ……！

ずんだもん：かつてのAI技術（RNNなど）は、文章を最初から順番に1文字ずつ処理していたのだ。だから「昔々あるところにおじいさんとおばあさんが……」と長文を読むと、最後の方には最初のおじいさんのことを忘れちゃう弱点があったし、処理スピードも遅かったのだ。

めたん：鳥頭すぎない？ それじゃあ長い会話なんて無理ね。

ずんだもん：そこでTransformerは、「Self-Attention（自己注意機構）」という必殺技を使ったのだ。これを使うと、文章の中のすべての単語を、いっぺんに同時に見渡すことができるようになったのだ！

めたん：全部同時に！？ それってどういうこと？

ずんだもん：文字通り、すべての単語がそれぞれ、他のすべての単語と「どれくらい関連しているか」を計算するのだ。たとえば、「銀行でお金を下ろす」の「銀行」と、「川の銀行で休む」の「銀行」……あ、英語だとどちらもBank（バンク）だけど。

めたん：ああ、「金融機関」のバンクと、「土手」のバンクね。単語だけ見たらどっちかわからないわね。

ずんだもん：そうなのだ。でもSelf-Attentionは、周りの単語を同時に見渡すのだ。「お金」や「下ろす」という単語があれば、「あ、今回はそっちと強く関係しているな」とスコア計算して、「これは金融機関のバンクだ！」と文脈を読み取ることができるのだ。

めたん：文脈を数字のスコアで理解してるってことね！ でも、どうやって計算してるの？

ずんだもん：ここでさっきの「埋め込み」で作った数字のベクトルが活躍するのだ。各トークンは、「Query（クエリ：検索・質問）」「Key（キー：鍵・名札）」「Value（バリュー：中身）」という３つのベクトルを新しく作り出すのだ。

めたん：クエリ、キー、バリュー。横文字が多くなってきたわ。

ずんだもん：合コンで例えるのだ！ クエリは「僕はこういう人が好きです！」という自分の希望。キーは「私はこういう人間です！」というアピールポイントの名札。そして全員のクエリとキーを掛け合わせて、相性（Attention Score）を計算するのだ。相性が良ければ、その人のバリュー（中身の情報）を自分の中に強くブレンドするのだ。

めたん：なるほど！ 単語同士で合コンして、「私とお前は相性がいいから、お前の情報を私に混ぜてやるぜ！」ってやってるのね。例えが独特だけどわかりやすいわ！

ずんだもん：さらに「Multi-Head Attention（マルチヘッド・アテンション）」と言って、この合コンを異なる趣味のグループで同時に何十個も並行して行うのだ。「文法の関係」を見るグループ、「感情の関係」を見るグループみたいに、いろんな視点から文脈を分析するのだ。

めたん：徹底的に単語同士の関係性を洗い出してるのね。

ずんだもん：そして、このAttentionが終わったら、Transformerの内部構造ではさらにデータを微調整する「レイヤー正規化（Layer Normalization）」や、データが消えないようにする「残差接続（Residual Connection）」、そして複雑なパターン処理をする「フィードフォワード・ネットワーク（FFN）」という層を通すのだ。

めたん：ちょっと難しくなってきたわ。

ずんだもん：要するに、「Attentionで集めた周りの情報を整理整頓して、さらに深い意味合いとして練り上げる」という工程を、何十層にも渡って繰り返しているのだ。

めたん：ミルフィーユみたいに何層も何層も、情報の関係性をこねくり回してるってことね。

ずんだもん：その通りなのだ。こうして「東京の天気は？」という入力の裏にある深い文脈を、巨大な数字の塊として見事に構築し終えたのだ。しかし！ 文脈をこねくり回したAIが次にやることは、実はものすごく単純な作業なのだ。しかもその選び方に、AIが時々とんでもない「嘘」をつく原因が隠されているのだ。

めたん：えっ！ あんなに複雑な計算をしたのに、次は単純なの？ しかも嘘をつく原因があるって……どういうこと？ 次も早く教えて！

---

## 【Block 4：ステップ④：「次の1文字を当てるゲーム」──確率分布とサンプリング】
<!-- 推定時間：4分 / 目標文字数：1,400文字 -->

ずんだもん：さあ、文脈を極限まで読み取った巨大な数字の塊が、どうやって僕たちの読める「答えの文章」になるのか。第四のステップなのだ。めたんは、AIが回答の文章を一気にズバーン！と作っていると思っていなかったのだ？

めたん：え？ 思ってたわよ。だってチャットの画面にパッと出てくるじゃない。

ずんだもん：実は違うのだ。LLMは、たったひとつのことしかしていない。「今まで入力された文章の続きとして、次に来る確率が一番高い『1トークン（1文字や言葉の断片）』を予測すること」これだけなのだ！

めたん：ええっ！？ つまり「1文字ずつ」作ってるの！？

ずんだもん：そうなのだ。「東京の」「天気は」「？」と入力されたら、その文脈の情報から計算して、LLMが持っている何万語という辞書の中から「次に来る言葉」の確率一覧表みたいなもの（確率分布）を作るのだ。

めたん：確率一覧表？

ずんだもん：たとえば、「晴」が40%、「曇」が30%、「雨」が20%、「本」が0.01%……みたいに、次に続きそうなトークンすべての確率を計算するのだ。

めたん：ああ、スマホの予測変換みたいなものね！ それの最強に頭がいいバージョンってこと？

ずんだもん：まさにそうなのだ！ この確率一覧表から、サンプリング（抽出処理）をして、次の言葉をひとつ選ぶのだ。たとえば一番確率の高い「晴」を選んだとするのだ。

めたん：ウンウン。

ずんだもん：そしたら次は、入力情報が「東京の」「天気は」「？」「晴」になるのだ。そしたらその「東京の天気は？晴」の文脈を再びAttentionのネットワークにぶち込んで、また確率計算をして、次の「れ」が来る確率を出す。そして選ばれた「東京の天気は？晴れ」をぶち込んで「で」を予測する……。これを延々とループで繰り返しているのだ！ これを専門用語で「自己回帰（Autoregressive）」型と呼ぶのだ。

めたん：ちょっと待って！ じゃあChatGPTがダーッと長い文章を書いてる時って、裏では「次はこの文字」「その次はこの文字」ってはちゃめちゃなスピードで予測ループをブン回してるだけなの！？

ずんだもん：おっしゃる通りなのだ！ そうやって1ステップずつ出力しているのだ。

めたん：信じられない……！ でも、一番確率が高い文字を選び続けるだけなら、同じ質問には毎回まったく同じ答えにならない？

ずんだもん：いい質問なのだ。実はここには「サイコロの目の重みづけ」みたいな遊びの仕掛けがあるのだ。「Temperature（温度）」や「Top-p」と呼ばれるパラメータなのだ。

めたん：温度？ AIが熱くなったりするの？

ずんだもん：ここでいう温度は「予測のランダムさ」なのだ。温度を低くすると、一番確率が高いガチガチの正解ばかり選ぶお堅い回答になる。温度を高くすると、あえて2番目や3番目に確率が高い言葉もランダムに選ぶようになって、多様でクリエイティブな文章を作れるようになるのだ。

めたん：なるほど！ わざと少し外した確率のものを選ぶから、AIは小説みたいなクリエイティブな文章も書けるのね。

ずんだもん：でも、ここに重大な落とし穴があるのだ。AIがもっともらしい嘘を堂々とついてしまう「ハルシネーション（幻覚）」という現象なのだ。

めたん：あ！ 歴史の出来事とかで大嘘を教えられたこと、私もあるわ！ あれはどうして起きるの？

ずんだもん：AIは「データベースから事実を検索して答えている」わけじゃないからなのだ。AIがやっているのは、あくまで「文脈として次に来ると自然な言葉」を確率で選んでいるだけなのだ。

めたん：あっ……！ 確率で選んだ言葉の並びが「自然」なだけであって、「事実」かどうかは確認してないってこと！？

ずんだもん：その通り！ だからAIは、自分の知らないことでも「分からない」と言う代わりに、手持ちの言葉の確率を繋ぎ合わせて「いかにもありそうな、自然な嘘の文」を作ってしまうのだ。これはサボっているわけじゃなくて、「次に来るもっともらしい言葉を予測しろ」というAIの根本的な仕組みによる、避けられない必然なのだ！

めたん：ひええ！ 「知ってる知識を検索して答える」んじゃなくて、「次にこの言葉が繋がってたら自然っぽいから出しちゃえ！」ってやってるのね。だからあんなに堂々と嘘をつけるんだ……。

ずんだもん：でもめたん。ただ確率で次の文字を当ててるだけのシステムが、どうしてプログラミングができたり、高度なクイズに答えられたりするのか不思議じゃないのだ？ この魔法を完成させるために、AIは想像を絶する「学習」というステップを踏んでいるのだ！

---

## 【Block 5：学習の秘密：事前学習・ファインチューニング・RLHF】
<!-- 推定時間：4分 / 目標文字数：1,300文字 -->

めたん：確かに、いくら「次はこれだ！」って当てるシステムが完璧でも、そもそもAI自身に基礎知識がないとトンチンカンな言葉しか予測できないわよね。どうやってあんなに賢くなったの？ インターネットを丸暗記してるってこと？

ずんだもん：違うのだ。LLMの学習は、大きく3つの段階に分かれているのだ。これを「基礎教育」「専門教育」「先輩の親身な指導」に分けて説明するのだ。

めたん：おお、学校みたいね。わかりやすい！

ずんだもん：まず第1段階は「事前学習（Pre-training）」。これが基礎教育なのだ。インターネット上にある、何百億何兆というものすごい量のテキストデータを読み込ませて、ひたすら「一部を隠して、次の文字を予測させる」クイズをやらせるのだ。

めたん：ネットの文章を片っ端から読み込ませるのね。

ずんだもん：最初はランダムに出力して間違えるけど、「間違えたらAIの内部の数値をちょこっと修正する」という作業を何兆回と繰り返すのだ。そうすると、AIは単なる暗記ではなく、言葉の背後にある「文法規則」や「パターン」、さらには「世界の一般的な知識」までを、巨大な数式の重み（パラメータ）として獲得するのだ！

めたん：丸暗記じゃなくて、法則を理解……いや、「汎化（はんか）」していくってことね！

ずんだもん：ちなみに、AIの賢さの規模はこの「パラメータの数」で表されるのだ。人間の脳のシナプスの数みたいなものなのだ。2018年に発表された初代「GPT-1」は1億ちょっとのパラメータだったけど、2020年の「GPT-3」はなんと1,750億個！ そして今の「GPT-4」なんかは非公開だけど「兆」を超えているとも言われているのだ。

めたん：規模の桁が違いすぎるわ……！ 莫大すぎる！

ずんだもん：で、第2段階が「ファインチューニング（微調整）」、専門教育なのだ。ネットの文章を読んだだけのAIは、質問しても「Q&Aサイトの続き」を書いちゃったりして、まだ使い勝手が悪いのだ。だから「質問にはこうやって対話形式で答えるんだよ」という質の高いお手本データを読ませて、対話の仕方を微調整するのだ。

めたん：なるほど、オタク知識を蓄えただけの状態から、接客マニュアルを教え込むのね。

ずんだもん：そして最後の第3段階、ここがChatGPTをあんなに人間っぽくしてブレイクさせた最大の鍵なのだ。「RLHF（人間のフィードバックによる強化学習）」という、先輩からの熱血指導なのだ！

めたん：人間のフィードバック？ 人間が直接指導するの？

ずんだもん：そうなのだ！ AIに出させた複数の答えを、人間のスタッフが「こっちの答えの方が親切だね」「こっちの答えは倫理的にアウト！」ってひたすら採点するのだ。その人間の採点基準を学習した「報酬モデル」という採点専用AIを作って、メインのAIをさらに特訓させるのだ。

めたん：ええっ、ベースの部分には人間の生の手作業がしっかり入っているのね。

ずんだもん：だからChatGPTは、ただ確率で言葉を繋ぐだけの冷たい機械から、僕たち人間が「心地よい」「役に立つ」と感じるように、徹底的に価値観を躾けられているのだ。

めたん：ただのネットの丸暗記じゃなくて、予測の法則を学んで、会話の仕方を学んで、人間の価値観まで教え込まれている……。だからあんなに自然なんだわ！

ずんだもん：インプットからアウトプット、そして学習の仕組みまで、これで全ての道のりを辿り終えたのだ！ ここまでのすべてを振り返ると、最初のあの「問い」の答えが、はっきりと見えてくるはずなのだ。

---

## 【Block 6：まとめ：「理解していないのに、なぜ賢く見えるのか」】
<!-- 推定時間：2分 / 目標文字数：800文字 -->

めたん：最初の問いって、「ChatGPTは文章の意味を1ミリも理解していない」ってやつよね。

ずんだもん：そうなのだ。今日見てきたプロセスを振り返るのだ。

めたん：ええと、入力された文字は「トークン化」されて「埋め込みベクトル」という数字の座標になり、「Attention」でお互いの関係性を計算される。そして最後はその結果を取り込んで「次に来る1文字の確率を予測する」のをループさせて文章をつなげていく……。

ずんだもん：まさにそうなのだ。AIの内部には「心を込めた配慮」も「事実を格納した辞書」もない。文章の意味を僕たち人間みたいに想像して「理解」しているわけではないのだ。やっていることは、巨大な数字ベクトル同士の計算と、「次はこの文字が来る確率が高い」という予測処理だけなのだ。

めたん：本当に、徹底的な「確率的オウム」だったのね……なんだかちょっとショックかも。でも、それなのにあんなに賢く見えるのはどうしてなの？

ずんだもん：それは、学習させたデータ量とパラメータ数が想像を絶する超巨大スケールだからなのだ。インターネット上のありとあらゆる人類の言葉のパターンを吸収しすぎた結果、「統計的に最も自然な言葉の連なり」を出力すると、それが人間から見れば「まるで完璧に意味を理解しているかのように」見えてしまうという、ある種のイリュージョンなのだ！

めたん：なんか凄い規模の話ね……。本当に意味なんてわからなくても、パターンの抽出を極致までやれば、それは表面上は「知能」と見分けがつかないってことだわ。

ずんだもん：最近ではAIを動かす推論の計算コストも、企業努力で1年で約90%も安くなったりして、この驚異のオウムたちはどんどん世界中に広まっているのだ！ でも、これらを動かすためのデータセンターの莫大な電力消費といった環境への影響など、新たな課題もあるのだ。

めたん：ただ魔法の箱として使うだけじゃなく、こうやって中身の仕組みを正しく知ることが大事なのね。今日でAIの中身のブラックボックスがすっかり開いた気がするわ。次に「大嘘」をつかれた時も、「あ、変な確率を選んじゃったな」って優しく見守れそうね。

ずんだもん：そういうことなのだ！ 「AIは理解しているわけではなく、確率で次の言葉を予測しているだけ」という本当の姿を理解して、正しい距離感でAIを使いたおしていくのだ！ それでは今日の解説はここまでなのだ〜！

めたん：次回の動画も絶対見てね！ バイバーイ！
